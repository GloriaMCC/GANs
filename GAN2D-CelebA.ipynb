{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14466,
     "status": "ok",
     "timestamp": 1678829247192,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "b2wQ90VjLSa1",
    "outputId": "b91791ab-fc89-4a7d-fea9-6039e17967f4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "def print_info():\n",
    "    print('  Versión de TensorFlow: {}'.format(tensorflow.__version__))\n",
    "    print('  GPU: {}'.format([x.physical_device_desc for x in device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "    print('  Versión Cuda  -> {}'.format(tensorflow.sysconfig.get_build_info()['cuda_version']))\n",
    "    print('  Versión Cudnn -> {}\\n'.format(tensorflow.sysconfig.get_build_info()['cudnn_version']))\n",
    "\n",
    "print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1678829232394,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "85b08KN80JKj"
   },
   "outputs": [],
   "source": [
    "#Import from library\n",
    "from datetime import date, time, datetime\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "from numpy import savez_compressed\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "#Importar librerias\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "# example of loading the mnist dataset\n",
    "from keras.datasets.mnist import load_data\n",
    "# load saved models\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image as an rgb array\n",
    "def load_image(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory, n_faces):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # load the image\n",
    "        pixels = load_image(directory + filename)\n",
    "        # store\n",
    "        faces.append(pixels)\n",
    "        # stop once we have enough\n",
    "        if len(faces) >= n_faces:\n",
    "            break\n",
    "    return asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a list of loaded faces\n",
    "def plot_faces(faces, n):\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(faces[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory that contains all images\n",
    "directory = 'celeba/'\n",
    "# load and extract all faces\n",
    "faces = load_faces(directory, 25)\n",
    "print('Loaded: ', faces.shape)\n",
    "# plot faces\n",
    "plot_faces(faces, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the face from a loaded image and resize\n",
    "def extract_face(model, pixels, required_size=(80, 80)):\n",
    "    # detect face in the image\n",
    "    faces = model.detect_faces(pixels)\n",
    "    # skip cases where we could not detect a face\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    # extract details of the face\n",
    "    x1, y1, width, height = faces[0][✬box✬]\n",
    "    # force detected pixel values to be positive (bug fix)\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    # convert into coordinates\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # retrieve face pixels\n",
    "    face_pixels = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face_pixels)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory, n_faces):\n",
    "    # prepare model\n",
    "    model = MTCNN()\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # load the image\n",
    "        pixels = load_image(directory + filename)\n",
    "        # get face\n",
    "        face = extract_face(model, pixels)\n",
    "        if face is None:\n",
    "            continue\n",
    "        # store\n",
    "        faces.append(face)\n",
    "        print(len(faces), face.shape)\n",
    "        # stop once we have enough\n",
    "        if len(faces) >= n_faces:\n",
    "            break\n",
    "    return asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory that contains all images\n",
    "directory = 'celeba/''\n",
    "# load and extract all faces\n",
    "all_faces = load_faces(directory, 50000)\n",
    "print('Loaded: '', all_faces.shape)\n",
    "# save in compressed format\n",
    "savez_compressed('img_celeba.npz', all_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1678829249256,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "MJMHlJyB0Z04"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos el modelo del discriminador\n",
    "def define_discriminator(in_shape=(80,80,3)):\n",
    "    # Red Convolucional\n",
    "    model = Sequential()\n",
    "    # normal\n",
    "    model.add(Conv2D(128, # Numero de Filtros\n",
    "                     (5,5), # Tamaño del Kernel\n",
    "                     padding='same',\n",
    "                     input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 40x40\n",
    "    model.add(Conv2D(128,\n",
    "                     (5,5),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 20x30\n",
    "    model.add(Conv2D(128,\n",
    "                     (5,5),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 10x10\n",
    "    model.add(Conv2D(128,\n",
    "                     (5,5),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # downsample to 5x5\n",
    "    model.add(Conv2D(128,\n",
    "                     (5,5),\n",
    "                     strides=(2,2),\n",
    "                     padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Droupout(0.4))\n",
    "    model.add(Dense(1,\n",
    "                    activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    #compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1678829249257,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "c78VIx0f0dGq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos el modelo del Generador\n",
    "def define_generator(latent_dim):\n",
    "   \n",
    "    #Definimos el modelo\n",
    "    model = Sequential()\n",
    "    #foundation for 7x7 image\n",
    "    n_nodes =128 *5*5 #features maps*dimensions\n",
    "    model.add(Dense(n_nodes,\n",
    "                    input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((5, 5, 128)))\n",
    "    # upsample to 10x10\n",
    "    model.add(Conv2DTranspose(128,\n",
    "                              (4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same'\n",
    "                              ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 20x20\n",
    "    model.add(Conv2DTranspose(128,\n",
    "                              (4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same'\n",
    "                              ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 40x40\n",
    "    model.add(Conv2DTranspose(128,\n",
    "                              (4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same'\n",
    "                              ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 80x80\n",
    "    model.add(Conv2DTranspose(128,\n",
    "                              (4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same'\n",
    "                              ))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # output 80x80x3\n",
    "    model.add(Conv2D(3,\n",
    "                     (5,5),\n",
    "                     activation='tanh',\n",
    "                     padding='same'\n",
    "                     ))\n",
    "              \n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1678829249259,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "ptOX3O840gJV"
   },
   "outputs": [],
   "source": [
    "\n",
    "#define the combined generator and dicriminatro model,\n",
    "#for updating the generator\n",
    "def define_gan(g_model,d_model):\n",
    "    #Hacenis que los pesos del discriminador no sean entrenables\n",
    "    d_model.trainable = False\n",
    "    #connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    #add the discriminator\n",
    "    model.add(d_model)\n",
    "    model.summary()\n",
    "    #compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1678829249260,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "vhqVhZ3Y0iYa"
   },
   "outputs": [],
   "source": [
    "\n",
    "## load and prepare mnist training images\n",
    "def load_real_samples():\n",
    "    # load the face dataset\n",
    "    data = load('img_celeba.npz')\n",
    "    X = data['arr_0']\n",
    "    # convert from unsigned ints to floats\n",
    "    X = X.astype('float32')\n",
    "    # scale from [0,255] to [0,1]\n",
    "    #X = X / 255.0\n",
    "    #scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1678829249262,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "Aa_dROvl0kaI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate ✬real✬ class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1678829249263,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "eyw9oM5d0mvq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1678829249264,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "5svu-cjb0owm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = g_model.predict(x_input)\n",
    "    # create ✬fake✬ class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1678829249265,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "Oig5pXRH0qwy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n, 1+i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(examples[i, :, :, 0],\n",
    "                   cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = 'results/generated_DGANCeleba_plot_e%03d.png' % (epoch+1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d_hist, g_hist, a_hist):\n",
    "    # plot loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(d_hist, label='dis')\n",
    "    plt.plot(g_hist, label='gen')\n",
    "    plt.legend()\n",
    "    # plot discriminator accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(a_hist, label='acc')\n",
    "    plt.legend()\n",
    "    # save plot to file\n",
    "    plt.savefig('results/plot_line_plot_loss_Celeba.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1678829249267,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "tm-OLDHH0s0t"
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, latent_dim, n_samples=100):\n",
    "    # prepare fake examples\n",
    "    x_fake, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    #x_fake = (x_fake + 1) / 2.0  \n",
    "    #save data\n",
    "    save_plot(x_fake, epoch)\n",
    "    # save the generator model tile file\n",
    "    filename = 'results/generator_Celeba_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1678829249268,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "m1Sy7Mnu0vJE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim,\n",
    "          n_epochs=10, n_batch=128):\n",
    "    # calculate the number of batches per epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the total iterations based on batch and epoch\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the number of samples in half a batch\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # prepare lists for storing stats each iteration\n",
    "    d_hist, g_hist, a_hist = list(), list(), list()\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # Train the discriminator \n",
    "        ## get randomly selected real samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        # generate fake examples\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        ## combine into one batch\n",
    "        X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "        # update discriminator model weights\n",
    "        d_loss, d_acc = d_model.train_on_batch(X, y)\n",
    "            \n",
    "        #Train the generator\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        # update the generator via the discriminator✬s error\n",
    "        g_loss, _ = gan_model.train_on_batch(X_gan, y_gan)\n",
    "           \n",
    "        # summarize loss on this batch\n",
    "        print('>%d, d=%.3f, g=%.3f, a=%d' % (i+1, d_loss, g_loss, int(100*d_acc)))\n",
    "        # record history\n",
    "        d_hist.append(d_loss)\n",
    "        g_hist.append(g_loss)\n",
    "        a_hist.append(d_acc)\n",
    "        # evaluate the model performance every epoch\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)\n",
    "    plot_history(d_hist, g_hist, a_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4616918,
     "status": "ok",
     "timestamp": 1678833866155,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "LX4zhed60x3R",
    "outputId": "e99c1b86-43bb-4684-d614-33439b680377"
   },
   "outputs": [],
   "source": [
    "# make folder for results\n",
    "makedirs('results', exist_ok=True)\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "d_model = define_discriminator()\n",
    "# create the\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim,n_epochs=)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXY0hGzXGdtN"
   },
   "source": [
    "# Generacion de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1678833866156,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "M2INwdNdHUdJ"
   },
   "outputs": [],
   "source": [
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot_predict(examples, n):\n",
    "  # plot images\n",
    "  for i in range(n * n):\n",
    "    # define subplot\n",
    "    plt.subplot(n, n, 1 + i)\n",
    "    # turn off axis\n",
    "    plt.axis('off')\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1678833867361,
     "user": {
      "displayName": "Gloria Campos",
      "userId": "00082261068174172380"
     },
     "user_tz": 360
    },
    "id": "5Qy0LMsiHoxX",
    "outputId": "4207beee-b723-431c-d1e9-b31f2480c761"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('results/generator_Celeba_model_936.h5')\n",
    "# generate images\n",
    "latent_points = generate_latent_points(100, 25)\n",
    "# generate images\n",
    "X = model.predict(latent_points)\n",
    "# plot the result\n",
    "save_plot_predict(X, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO07883rRxKN4mKTfVPli8J",
   "mount_file_id": "1_LCA5wXQHwt7kXyYIDwwk1nmgqyb8KQJ",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
